{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/deployment/deploy-to-local/register-model-deploy-local-advanced.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register model and deploy locally with advanced usages\n",
    "\n",
    "This example shows how to deploy a web service in step-by-step fashion:\n",
    "\n",
    " 1. Register model\n",
    " 2. Deploy the image as a web service in a local Docker container.\n",
    " 3. Quickly test changes to your entry script by reloading the local service.\n",
    " 4. Optionally, you can also make changes to model, conda or extra_docker_file_steps and update local service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the [configuration](../../../configuration.ipynb) Notebook first if you haven't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from gensim.summarization.textcleaner import split_sentences\n",
    "import joblib\n",
    "from sqlalchemy import create_engine\n",
    "from datasets import Dataset\n",
    "import copy\n",
    "import json\n",
    "\n",
    "from azureml.core import Run, Workspace, Model\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "from azureml.core.model import InferenceConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "\n",
    "Initialize a workspace object from persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "create workspace"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aci-eur-frc-aa-ss-mlw\n",
      "aci-eur-frc-aa-ss-rg\n",
      "francecentral\n",
      "19518d47-0c8b-4829-a602-c5ced78deb3f\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration, DockerConfiguration\n",
    "docker_configuration = DockerConfiguration(use_docker=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Run.get_context()\n",
    "keyvault = ws.get_default_keyvault()\n",
    "rp_env = Environment(name='rp')\n",
    "#rp_env.docker.enabled = True\n",
    "#rp_env.docker = docker_configuration\n",
    "rp_env.python.user_managed_dependencies = True\n",
    "rp_env.docker.base_image_registry.address = \"acieurfrcaassacr.azurecr.io\"\n",
    "rp_env.docker.base_image_registry.username = keyvault.get_secret(name='acieurfrcaassacr-admin-user')\n",
    "rp_env.docker.base_image_registry.password = keyvault.get_secret(name='acieurfrcaassacr-admin-pwd')\n",
    "rp_env.inferencing_stack_version = \"latest\"\n",
    "rp_env.docker.base_image = \"acieurfrcaassacr.azurecr.io/azureml-env-base-research-platform:latest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(entry_script=\"inference_search.py\",\n",
    "                                   environment=rp_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model as a Local Docker Web Service\n",
    "\n",
    "*Make sure you have Docker installed and running.*\n",
    "\n",
    "Note that the service creation can take few minutes.\n",
    "\n",
    "NOTE:\n",
    "\n",
    "The Docker image runs as a Linux container. If you are running Docker for Windows, you need to ensure the Linux Engine is running:\n",
    "\n",
    "    # PowerShell command to switch to Linux engine\n",
    "    & 'C:\\Program Files\\Docker\\Docker\\DockerCli.exe' -SwitchLinuxEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_model_name = 'c19gq_ance_msmarco_passage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(ws, neural_model_name, version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import LocalWebservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is optional, if not provided Docker will choose a random unused port.\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.core.webservice.local.LocalWebserviceDeploymentConfiguration at 0x7f282c227790>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#docker container prune -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model c19gq_ance_msmarco_passage:1 to /tmp/azureml_vqe8cfsd/c19gq_ance_msmarco_passage/1\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry acieurfrcaassacr.azurecr.io\n",
      "Logging into Docker registry acieurfrcaassacr.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM acieurfrcaassacr.azurecr.io/azureml/azureml_035bb21c11fc36791a93f138d46a324c\n",
      " ---> be6a190a2700\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 0ba8c22da2ca\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjE5NTE4ZDQ3LTBjOGItNDgyOS1hNjAyLWM1Y2VkNzhkZWIzZiIsInJlc291cmNlR3JvdXBOYW1lIjoiYWNpLWV1ci1mcmMtYWEtc3MtcmciLCJhY2NvdW50TmFtZSI6ImFjaS1ldXItZnJjLWFhLXNzLW1sdyIsIndvcmtzcGFjZUlkIjoiMzA0ODQ5MmEtZWQ4MC00NGU1LThhZDAtNzc0YjhiNTIzMDY5In0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 0e180ff72335\n",
      " ---> 655307f70090\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpgv3rf6t6.py' /var/azureml-app/main.py\n",
      " ---> Running in 53f178cbf720\n",
      " ---> 345a4b7a4de6\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in ce782b4cde94\n",
      " ---> 06a870d6711e\n",
      "Successfully built 06a870d6711e\n",
      "Successfully tagged test:latest\n",
      "Container (name:zen_nightingale, id:5404a7cec5e46288d9495afb9bf1c7100197093e53356013dbc24f752801a5a1) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:797bbbd6f8ceaeb921f12cc7876b6ee2ca0047bc4a8a4397b91a947422245d73 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n"
     ]
    }
   ],
   "source": [
    "local_service = model.deploy(ws, \"test\", [model], inference_config, deployment_config)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": [
     "deploy service",
     "aci"
    ]
   },
   "source": [
    "local_service.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local service port: 6789\n"
     ]
    }
   ],
   "source": [
    "print('Local service port: {}'.format(local_service.port))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Status and Get Container Logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-04T06:41:05,881545987+00:00 - gunicorn/run \n",
      "2021-06-04T06:41:05,881622188+00:00 - iot-server/run \n",
      "2021-06-04T06:41:05,881627378+00:00 - rsyslog/run \n",
      "2021-06-04T06:41:05,882324661+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-06-04T06:41:05,924562745+00:00 - iot-server/finish 1 0\n",
      "2021-06-04T06:41:05,925354179+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "File not found: /var/azureml-app/.\n",
      "Starting HTTP server\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (13)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 75\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Loading faiss with AVX2 support.\n",
      "Successfully loaded faiss with AVX2 support.\n",
      "Initializing logger\n",
      "2021-06-04 06:41:08,205 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2021-06-04 06:41:08,205 | root | INFO | Starting up request id generator\n",
      "2021-06-04 06:41:08,205 | root | INFO | Starting up app insight hooks\n",
      "2021-06-04 06:41:08,205 | root | INFO | Invoking user's init function\n",
      "Inference Init\n",
      "no request id,Inference Init\n",
      "\n",
      "2021-06-04 06:41:09,692 | azureml._restclient.clientbase | INFO | Created a worker pool for first use\n",
      "Created a worker pool for first use\n",
      "Load pretrained SentenceTransformer: azureml-models/c19gq_ance_msmarco_passage/1/c19gq_model\n",
      "Load SentenceTransformer from folder: azureml-models/c19gq_ance_msmarco_passage/1/c19gq_model\n",
      "You try to use a model that was created with version 1.1.1, however, your version is 1.1.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "Use pytorch device: cpu\n",
      "Lock 139926299623952 acquired on /root/.cache/huggingface/transformers/e7a41a6174913880df8e829b641066e966206fab8954ee632010d4f61628ae02.f0aa8e636bcccae4be6e2271678827e07b888454c0bc3f0a300929ab2bc621b3.lock\n",
      "\r",
      "Downloading:   0%|          | 0.00/791 [00:00<?, ?B/s]\n",
      "no request id,\r",
      "Downloading:   0%|          | 0.00/791 [00:00<?, ?B/s]\n",
      "\n",
      "no request id,\r",
      "Downloading: 100%|██████████| 791/791 [00:00<00:00, 1.07MB/s]\n",
      "\n",
      "\r",
      "Downloading: 100%|██████████| 791/791 [00:00<00:00, 1.07MB/s]\n",
      "Lock 139926299623952 released on /root/.cache/huggingface/transformers/e7a41a6174913880df8e829b641066e966206fab8954ee632010d4f61628ae02.f0aa8e636bcccae4be6e2271678827e07b888454c0bc3f0a300929ab2bc621b3.lock\n",
      "Lock 139926290207888 acquired on /root/.cache/huggingface/transformers/95b5278c279acc639033aedc8f911cf140f060b2d24d4cf8ddf17522046b0309.6f727c8743dc3bf284f7ad6c96294591fb8305c94d71a2babe33c6f8f249956c.lock\n",
      "\r",
      "Downloading:   0%|          | 0.00/134M [00:00<?, ?B/s]\n",
      "no request id,\r",
      "Downloading:   0%|          | 0.00/134M [00:00<?, ?B/s]\n",
      "\n",
      "\r",
      "Downloading:   5%|▍         | 6.32M/134M [00:00<00:02, 63.2MB/s]\n",
      "no request id,\r",
      "Downloading:   5%|▍         | 6.32M/134M [00:00<00:02, 63.2MB/s]\n",
      "\n",
      "\r",
      "Downloading:  12%|█▏        | 15.5M/134M [00:00<00:01, 80.1MB/s]\n",
      "no request id,\r",
      "Downloading:  12%|█▏        | 15.5M/134M [00:00<00:01, 80.1MB/s]\n",
      "\n",
      "\r",
      "Downloading:  19%|█▊        | 24.9M/134M [00:00<00:01, 86.3MB/s]\n",
      "no request id,\r",
      "Downloading:  19%|█▊        | 24.9M/134M [00:00<00:01, 86.3MB/s]\n",
      "\n",
      "no request id,\r",
      "Downloading:  26%|██▌       | 34.2M/134M [00:00<00:01, 89.0MB/s]\n",
      "\n",
      "\r",
      "Downloading:  26%|██▌       | 34.2M/134M [00:00<00:01, 89.0MB/s]\n",
      "\r",
      "Downloading:  33%|███▎      | 43.7M/134M [00:00<00:00, 91.2MB/s]\n",
      "no request id,\r",
      "Downloading:  33%|███▎      | 43.7M/134M [00:00<00:00, 91.2MB/s]\n",
      "\n",
      "no request id,\r",
      "Downloading:  40%|███▉      | 53.3M/134M [00:00<00:00, 92.8MB/s]\n",
      "\n",
      "\r",
      "Downloading:  40%|███▉      | 53.3M/134M [00:00<00:00, 92.8MB/s]\n",
      "\r",
      "Downloading:  47%|████▋     | 62.9M/134M [00:00<00:00, 93.7MB/s]\n",
      "no request id,\r",
      "Downloading:  47%|████▋     | 62.9M/134M [00:00<00:00, 93.7MB/s]\n",
      "\n",
      "no request id,\r",
      "Downloading:  54%|█████▍    | 72.5M/134M [00:00<00:00, 94.5MB/s]\n",
      "\n",
      "\r",
      "Downloading:  54%|█████▍    | 72.5M/134M [00:00<00:00, 94.5MB/s]\n",
      "no request id,\r",
      "Downloading:  62%|██████▏   | 82.2M/134M [00:00<00:00, 95.2MB/s]\n",
      "\n",
      "\r",
      "Downloading:  62%|██████▏   | 82.2M/134M [00:00<00:00, 95.2MB/s]\n",
      "no request id,\r",
      "Downloading:  69%|██████▊   | 91.8M/134M [00:01<00:00, 95.5MB/s]\n",
      "\n",
      "\r",
      "Downloading:  69%|██████▊   | 91.8M/134M [00:01<00:00, 95.5MB/s]\n",
      "no request id,\r",
      "Downloading:  76%|███████▌  | 101M/134M [00:01<00:00, 95.3MB/s]\n",
      "\n",
      "\r",
      "Downloading:  76%|███████▌  | 101M/134M [00:01<00:00, 95.3MB/s]\n",
      "no request id,\r",
      "Downloading:  83%|████████▎ | 111M/134M [00:01<00:00, 94.9MB/s]\n",
      "\n",
      "\r",
      "Downloading:  83%|████████▎ | 111M/134M [00:01<00:00, 94.9MB/s]\n",
      "\r",
      "Downloading:  90%|█████████ | 120M/134M [00:01<00:00, 92.9MB/s]\n",
      "no request id,\r",
      "Downloading:  90%|█████████ | 120M/134M [00:01<00:00, 92.9MB/s]\n",
      "\n",
      "\r",
      "Downloading:  97%|█████████▋| 130M/134M [00:01<00:00, 93.2MB/s]\n",
      "no request id,\r",
      "Downloading:  97%|█████████▋| 130M/134M [00:01<00:00, 93.2MB/s]\n",
      "\n",
      "no request id,\r",
      "Downloading: 100%|██████████| 134M/134M [00:01<00:00, 92.3MB/s]\n",
      "\n",
      "\r",
      "Downloading: 100%|██████████| 134M/134M [00:01<00:00, 92.3MB/s]\n",
      "Lock 139926290207888 released on /root/.cache/huggingface/transformers/95b5278c279acc639033aedc8f911cf140f060b2d24d4cf8ddf17522046b0309.6f727c8743dc3bf284f7ad6c96294591fb8305c94d71a2babe33c6f8f249956c.lock\n",
      "Lock 139923869580496 acquired on /root/.cache/huggingface/transformers/f003ccedef902488d289f1be2e19bb6bc1fe1d29a9a59b41662e4077e6835c23.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "no request id,\r",
      "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]\n",
      "\n",
      "\r",
      "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]\n",
      "no request id,\r",
      "Downloading:  46%|████▋     | 108k/232k [00:00<00:00, 1.08MB/s]\n",
      "\n",
      "\r",
      "Downloading:  46%|████▋     | 108k/232k [00:00<00:00, 1.08MB/s]\n",
      "no request id,\r",
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 1.22MB/s]\n",
      "\n",
      "Lock 139923869580496 released on /root/.cache/huggingface/transformers/f003ccedef902488d289f1be2e19bb6bc1fe1d29a9a59b41662e4077e6835c23.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "\r",
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 1.22MB/s]\n",
      "Lock 139923869580496 acquired on /root/.cache/huggingface/transformers/c564220d5d9da1ed8041a9bfa652d37dc347285f5825ad9fdf3b90f2774df756.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d.lock\n",
      "\r",
      "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]\n",
      "no request id,\r",
      "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]\n",
      "\n",
      "no request id,\r",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 130kB/s]\n",
      "\n",
      "\r",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 130kB/s]\n",
      "Lock 139923869580496 released on /root/.cache/huggingface/transformers/c564220d5d9da1ed8041a9bfa652d37dc347285f5825ad9fdf3b90f2774df756.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d.lock\n",
      "Lock 139924996626384 acquired on /root/.cache/huggingface/transformers/7d7a4258af03e2131364f33e60843128593a623174122bc7dd8d9ed78882b094.d4f6d1f97a6ac0a14be4b1f9ad30902907d930c88da424ede8f167a4afe3053a.lock\n",
      "\r",
      "Downloading:   0%|          | 0.00/316 [00:00<?, ?B/s]\n",
      "no request id,\r",
      "Downloading:   0%|          | 0.00/316 [00:00<?, ?B/s]\n",
      "\n",
      "\r",
      "Downloading: 100%|██████████| 316/316 [00:00<00:00, 460kB/s]\n",
      "no request id,\r",
      "Downloading: 100%|██████████| 316/316 [00:00<00:00, 460kB/s]\n",
      "\n",
      "Lock 139924996626384 released on /root/.cache/huggingface/transformers/7d7a4258af03e2131364f33e60843128593a623174122bc7dd8d9ed78882b094.d4f6d1f97a6ac0a14be4b1f9ad30902907d930c88da424ede8f167a4afe3053a.lock\n",
      "Use pytorch device: cpu\n",
      "2021-06-04 06:41:28,601 | root | INFO | Users's init has completed successfully\n",
      "2021-06-04 06:41:28,602 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-06-04 06:41:28,602 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-06-04 06:41:28,602 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(local_service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container has been successfully cleaned up.\n",
      "Starting Docker container...\n",
      "Docker container running.\n"
     ]
    }
   ],
   "source": [
    "local_service.reload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Service\n",
    "\n",
    "If you want to change your model(s), Conda dependencies, or deployment configuration, call `update()` to rebuild the Docker image.\n",
    "\n",
    "```python\n",
    "\n",
    "local_service.update(models=[SomeOtherModelObject],\n",
    "                     deployment_config=local_config,\n",
    "                     inference_config=inference_config)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container (name:thirsty_nobel, id:3e352b72ecbe41e18c3b68a26ba50abfe580e6cf0776489a0942bdbde474765f) cannot be killed.\n",
      "Container has been successfully cleaned up.\n"
     ]
    }
   ],
   "source": [
    "local_service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "keriehm"
   }
  ],
  "kernelspec": {
   "display_name": "pybase",
   "language": "python",
   "name": "pybase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
